\documentclass{article}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{xr}
\usepackage{xcite}
\externalcitedocument{Thesis}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newcommand{\qed}{$\blacksquare$}

\externaldocument{ch1}
\externaldocument{ch1-5}
\externaldocument{ch2}

\begin{document}

\title{Réponse aux remarques de Jérôme Pouyet}
\author{Alexis Bergès}

\maketitle

Les chapitres sont mieux reliés les uns aux autres, avec des résumés plus exhaustifs de leur contribution, des paragraphes de liaison en début et en fin de chaque chapitre, et des références aux terminologies des autres chapitres dans le corps du texte sur les questions d'incertitude notamment.\\

Le code utilisé dans le chapitre 3 est maintenant joint en annexe de la thèse.\\

Conclusion ajoutée, et beaucoup de typos corrigées.\\

\section{Chapitre 1}
\begin{itemize}
\item \textbf{Citer le travail de John Rust sur les coûts de maintenance des centrales nucléaires.}\\

Ajout au paragraphe \ref{dayaheadintro}:

\begin{quote}
The industry is aware of these effects \cite{GE}, as well as the litterature, although it focuses mainly on other types of effects, such as the impact on shutdown due to maintenance \cite{rothwell1995dynamic}, some B2B companies even specialize in minimizing the related long term costs.
\end{quote}

\item \textbf{Préciser la délimitation entre ce qui relève du calcul sotchastique standard et de ce qui est de l'ordre de l'apport de ce chapitre.}\\

Ajout d'un paragraphe en conclusion de la partie \ref{sec_ramping_costs}.

\begin{quote}
We want to note that all the stochastic calculus presented here is very standard, our contribution is in noting the low-pass filter effect of the physical power plant on fluctuations which allow us to obtain convergent expressions.
\end{quote}

\item \textbf{Ajouter une référence bibliographique de référence pour le calcul stochastique.}\\

Ajout lors de l'introduction de la formule d'Euler Maruyama dans la partie \ref{sec_ramping_costs}.
\begin{quote}
We are therefore going to first consider the discrete case of a random walk of timestep $\Delta t$ which converges towards the It\={o} process \ref{sdegen}, using the Euler-Maruyama approximation \cite{kloeden2011numerical}, a generalization of the Euler method to stochastic differential equations. \\

This formula can be found on page 305. This book focuses on numerical approximations of continuous stochastic processes, which is the reverse of what we are doing here, but it is only in such numeric-centric books that this scheme is introduced. For a more general approach to stochastic differentiel equations, see \cite{oksendal2003stochastic}.
\end{quote}

\item \textbf{Est-il justifié de prendre des coûts dynamiques symmétriques ? }\\

Nous reconnaissons dans la partie \ref{sec_ramping_costs} que les coûts dynamiques ne doivent pas nécessairement être quadratiques, mais que par contre le premier terme de leur développement limité doit l'être, par un argument de symmétrie. Nous justifions donc ainsi notre choix de coûts quadratiques : s'ils ne sont pas quadratiques, un terme quadratique est le premier terme non nul dans une approximation polynomiale de leur forme, et doit donc nous permettre de capturer un certain nombre de leurs effets.

\item \textbf{Définir le problème d'Euler Lagrange.}\\

Ajout de la note de bas de page suivante dans la partie \ref{heur}:

\begin{quote}
The Euler–Lagrange equation is an equation satisfied by a function  $p$ of a real argument $\theta$, which is a stationary point of the functional:

$$ S(q) = \int_a^b \mathcal{L}(\theta,p(\theta),\dot{p}(\theta))dt$$

where:
\begin{enumerate}
\item $p$ is the function to be found:
\begin{align*}
p \colon [a,b] \subset \mathbb{R} &\to X\\
\theta & \mapsto x=p(\theta)
\end{align*}
s.t. $p$ is differentiable
\item $\dot{p}$ is the derivative of $p$ w.r.t. $\theta$:
\begin{align*}
\dot{p} \colon [a,b] &\to T_{p(\theta)}X\\
\theta & \mapsto v=\dot{p}(\theta)
\end{align*}
$T_{p(\theta)}X$ denotes the tangent space to $X$ at the point $p(\theta)$.
\item $\mathcal{L}$ is a real-valued function with continuous first derivatives:
\begin{align*}
\mathcal{L} \colon [a,b] \times TX &\to\mathbb{R}\\
(\theta,x,v) & \mapsto \mathcal{L}(\theta,x,v)
\end{align*}
$T_{p(\theta)}X$ denotes the tangent space to $X$ at the point $p(\theta)$.
\end{enumerate}
\end{quote}

\item \textbf{Pourquoi dans le cas du monopole nous évoquons que la solution n'est déjà plus ex-post optimale alors que la solution ne dépend pas de la distribution des chocs ?}\\

Les résultats de la proposition \ref{monopequilibria} dépendent des chocs, mais nous avons paramétrisé ces chocs par $a$ et $b$ tandis que la distribution de $\theta$ reste constante entre $[-1,1]$. Néanmoins les chocs de demande ont pour forme $a\theta +b$ et la solution exhibe bien une dépendance sur ces paramètres. Nous ajoutons la phrase suivante dans la propriété pour lever l'ambiguité:

\begin{quote}
These expressions depend explicitly on our parametrization of the shocks by the parameters $a$ and $b$.
\end{quote}

\item \textbf{Adoucir la formule sur les méthodes numériques en économie en conclusion de la discussion sur les limites du modèle \ref{limits}.}\\

Nouvelle formulation:

\begin{quote}
More generally, I think numerical methods as a guide for theoretical results have not been exploited to the fullest of their potential.  
\end{quote}

\item \textbf{Quel pourrait être l'impact sur le market design de l'existence de ramping costs ?}\\

Ex-nihilo, cela laisserait entendre qu'un simple marché day-ahead n'est pas forcément suffisant, mais le marché n'a pas pris les résultats d'ex-post optimalité au pied de la lettre et a très vite ajouté des marchés avec des horizons temporels differents, notamment le marché intraday en plus du marché day-ahead, dont l'existence est un mystère dans des modèles ex-post optimaux. En pratique il n'y a donc pas particulièrement de conséquences de market design puisque les praticiens ne se sont pas appuyés sur cette conséquence des SFE dans le design des marchés, et que les théoriciens se sont bien gardés de considérer cette conséquence de l'ex-post optimalité comme suffisamment robuste pour recommander de ne pas faire de marchés avec des horizons temporels différents. J'évoque cela dans la conclusion du chapitre, partie \ref{ccl}, mais je ne vois donc pas ce résultat comme ayant de conséquence en market design à proprement parler. Dans le cas où notre modèle ouvrirait la voie à des modèles explorant l'interaction entre day-ahead et intraday, peut-être y aurait il des résultats sur le différentiel d'horizon temporel optimal étant donné les caractéristiques de la dynamique stochastique de la demande.
\end{itemize}

\section{Chapitre 2}
\begin{itemize}
\item \textbf{Plus de détails expliquant pourquoi on construit le proxy de l'incertitude météo via l'autocorrelation au paragraphe \ref{autocorr}.}\\

Ajout d'une explication détaillée:

\begin{quote}
We use this dataset to build measures of the weather uncertainty. To do so we measure the auto-correlation lengthscale of our three weather variables of interest: temperature, wind speed and light intensity. This lengthscale measures how much are the weather variables correlated spatially. Our hypothesis is that the auto-correlation lengthscale is inversely proportional to uncertainty about the variable we are interested in. When it is small, the variable is less spatially correlated, which we interpret as being more difficult to forecast. Conversely, when the auto-correlation lengthscale is large, the variable is very correlated spatially, that is that the informational content of one datapoint is higher for the prospect of using it for the evaluation of a national effect.\\

More precisely, the argument is as follows: \\

\textbf{First}, renewable production is built by aggregating the forecast of all individual renewable sources. This means knowing the position and capacity of every renewable source, querying weather forecasts for all of these points, modeling the renewable's response to the forecasted weather, and adding the forecasted productions. \\

\textbf{Second}, we note that weather is spatially correlated, which means that the closer two points are, the closer the values for a given weather variable (the air temperature at your left hand is very close to that at your left hand, but less so across the city, and even less so across the country). This correlation roughly follows an exponential law: the difference between the values of a weather variable between two points behaves in a linear fashion for small distances, and saturates at large distances.\footnote{Intuitively, the characteristic lengthscale of autocorrelation represents the distance required between two geographical points on a map of weather forecasts to observe a decorrelation of half of its maximum value. For example on the wind speeds prediction, a characteristic length of 80 km means that if we observe two very distant points (say 1000km) to have a difference in wind speeds of, on average, 50km/h (this being the maximum difference, we are in the saturated regime), then we will observe, on average, wind speed differences of 25km/h for points distant from each other by 80km.} The transition between those two regimes is given by a caracteristic lengthscale, a bit less than 200km on average. \\

\textbf{Third}, we observe that the average distance between production points is large enough that the relevant regime of autocorrelation is the saturated part.\footnote{For N production points, we compute the N(N-1)/2 pairs of points, consider their distances, and compute the average of these distances weighted by the production capacity at every point. In the case of the wind we have an average distance of 459 km, in the case of the photovoltaic production we have an average distance of 499km.} \\

\textbf{Fourth}, we note that there are two main channels through which the overall uncertainty about renewable production is related to the weather. There is an issue of error averaging, which means that if the weather becomes very spatially uncorrelated, one can expect errors to cancel out relative to a given bias in the forecast. This channel would tend to imply that more spatial variations imply a smaller uncertainty about production. There is also the issue that weather forecasts are numerical simulations and that the mesh size for such simulations, typically 5km for the high precision ARPEGE model of Météo France, implies that the errors are higher as the simulated phenomenons have higher gradients. This means in our case that the uncertainty about the forecast increases as the weather becomes more spatially uncorrelated. \\

\textbf{Fifth}, these two effects are of opposite signs, but our third point is an argument for considering that the averaging of errors is smaller than the simulation errors. Therefore we expect our uncertainty to increase as the spatial autocorrelation decreases (i.e. more spatial variation). \\

This can be summed up with the following hand-waving argument: when there is more spatial variations, the weather is more messy, therefore more difficult to predict. 
\end{quote}

\item \textbf{Détailler l'argument justifiant de l'emploi d'une méthodologie non paramétrique vs une approche cherchant a fitter des fonctions logistiques sur les données.}\\

Plus de détail apporté, notamment en évoquant la métrique que nous avons en tête lorsque nous évoquons que les données ne sont pas bien fittées par une fonction logistique, illustré en fig. \ref{assymetry}, mais aussi en détaillant ce que nous entendons par le fait qu'un fit paramétrique ``mélange'' de l'information de plusieurs parties de la courbe sur un paramètre.

\begin{quote}
Instead, we develop a non-parametric, functional data analysis approach to select comparable data points from the original bid functions. In our case, this selection of points will yield 4 regions for every curves, each region can be thought of as linear. These selected points are comparable across repetitions of the market (i.e. auctions for different hourly contracts) and can then be used to run a cross-sectional reduced form model. The interest of this approach is threefold. First, it aims to use as much of the original information as possible without distorting it into parameters of a logistic function. What we mean by distortion is the example displayed in Fig. \ref{assymetry}, where one can see that the fitted logistic function in green is very far from the data (in the sense that the integral of the absolute value of the difference of the two curves is very large) because the underlying data simply does not have the proper shape. Also, information about different parts of the bid function does not influence one another, contrary to a parametrized form in which one tries to fit a specified function to data. This implies that the error between the functional form and the data at any point of the curve influences the fitted parameters, therefore ``mixing'' information from the whole curve into the choice of a given value for the parameter. Second, our approach is “scalable” because as many points as necessary can be extracted. The cross-sectional analyses are then conditioned on the type of comparable points selected. Third, while our analysis provides support for an underlying tri-linear or S-shaped functional form, we do not need to assume a specific functional form nor impose overly simplistic assumptions, such as symmetry of the functional forms, to ensure convergence of the estimator.\\
\end{quote}

\end{itemize}

\section{Chapitre 3}
\begin{itemize}
\item \textbf{Quelle serait la prédiction théorique testable induite par KM dans notre contexte ? }\\

Détail ajouté dans la partie \ref{intropredict}:

\begin{quote}
We test the impact of uncertainty of supplier strategies by testing the prediction that suppliers bid steeper supply bid functions when faced with a larger uncertainty concerning the outcome of the (residual) demand realization, for which the traditional supply function equilibria framework provides no prediction at all, which means that our null hypothesis, tno effect of uncertainty of the slope, corresponds to the regular SFE framework.
\end{quote}

\item \textbf{Évoquer l'effet de ne pas tenir compte des interconnexions.}\\

Ajout dans l'introduction:

\begin{quote}
The importance of uncertainty for the expectation of dynamic costs is shown in chapter 1. Uncertainty itself on the electricity market as well as estimates for the value of ramping costs have been studied empirically by \cite{wolak2007quantifying}, in the case of step functions. We focus on two sources of uncertainty for traditional electricity suppliers, namely uncertainty about the realization of the market demand and uncertainty from the inherently unpredictable meteorological situation
(which affects renewables generation), mainly because those are the two main sources of uncertainty in the span of time covered by our data (2011-2013). There is one blind spot in our analysis: we do not have data about the interconnected countries, which themselves affect the French market, and therefore introduce another important of uncertainty. Not taking this effect into account essentially introduces noise in our data and means that we need more data to infer the significance of an effect compared to a case where we would be able to control for it. We propose a methodology to measure this uncertainty and its impact on firm strategies on the electricity market. 
\end{quote}
\end{itemize}



\end{document}
